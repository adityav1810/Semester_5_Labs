{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_1_Software_cost_estimation (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityav1810/Semester_5_Labs/blob/master/ECSE303L-AIandML/Lab10/Task_1_Software_cost_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yGvcerZa0S8"
      },
      "source": [
        "# Objective: Feature Subset Selection to Improve Software Cost Estimation\n",
        "\n",
        "## Dataset\n",
        "This is a PROMISE Software Engineering Repository data set made publicly available to encourage repeatable, verifiable, refutable, and/or improvable predictive models of software engineering. The main objective is to estimate the software cost estimation using feature subset selection techniques.\n",
        "\n",
        "## Attributes\n",
        "1.\tRELY {Nominal,Very_High,High,Low} \n",
        "2.\tDATA {High,Low,Nominal,Very_High} \n",
        "3.\tCPLX {Very_High,High,Nominal,Extra_High,Low} \n",
        "4.\tTIME {Nominal,Very_High,High,Extra_High} \n",
        "5.\tSTOR {Nominal,Very_High,High,Extra_High} \n",
        "6.\tVIRT {Low,Nominal,High}\n",
        "7.\tTURN {Nominal,High,Low}\n",
        "8.\tACAP {High,Very_High,Nominal} \n",
        "9.\tAEXP {Nominal,Very_High,High} \n",
        "10.\tPCAP {Very_High,High,Nominal}\n",
        "11.\tVEXP {Low,Nominal,High}\n",
        "12.\tLEXP {Nominal,High,Very_Low,Low} \n",
        "13.\tMODP {High,Nominal,Very_High,Low}\n",
        "14.\tTOOL {Nominal,High,Very_High,Very_Low,Low} \n",
        "15.\tSCED {Low,Nominal,High}\n",
        "16.\tLOC numeric \n",
        "\n",
        "## Target Class\n",
        "ACT_EFFORT numeric %17\n",
        "\n",
        "### Source: http://promise.site.uottawa.ca/SERepository/datasets/cocomonasa_v1.arff\n",
        "\n",
        "Tasks:\n",
        "1.\tObtain the software cost estimation dataset\n",
        "2.\tApply pre-processing techniques (if any)\n",
        "3.\tApply feature subset selection techniques such as correlation analysis, forward selection, backward elimination, recursive feature elimination etc. Find best possible subset of features from each method.\n",
        "4.\tDivide dataset into training and testing set, respectively.\n",
        "5.\tImplement support vector regression (SVR), Linear regression, and Decision tree.\n",
        "6.\tEnsemble SVR, Linear regression and Decision tree. \n",
        "7.\tEvaluate Coefficient of determination and Root mean square error for all the models including the ensemble one.\n",
        "8.\tConclude the results\n",
        "\n",
        "Helpful links: https://scikit-learn.org/stable/modules/ensemble.html\n",
        "https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/\n",
        "https://medium.com/pursuitnotes/support-vector-regression-in-6-steps-with-python-c4569acd062d\n",
        "https://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uFw2frEUF0y"
      },
      "source": [
        "## Task 1: Implementation of regression models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duh_Q74qIidS"
      },
      "source": [
        "# Load the libraries\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import sklearn\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "import math\n",
        "from sklearn import tree\n",
        "from sklearn.datasets import make_friedman1\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyioH2iYIjhk",
        "outputId": "3fc4e4ac-fcd4-4ddb-f1a6-08abe4d157bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fl = open(\"/content/week12lab1.txt\",\"r\") \n",
        "k=0\n",
        "for i in fl.readlines():\n",
        "    if(k==0):\n",
        "        dat=[x.strip() for x in i[:-22].split(',')]\n",
        "        data=np.array(dat)\n",
        "    k=1\n",
        "    temp=[x.strip() for x in i[:-22].split(',')]\n",
        "    temp=np.array(temp)\n",
        "    data = np.vstack ((data, temp) )\n",
        "    print([x.strip() for x in i[:-22].split(',')])\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Nominal', 'High', 'Very_High', 'Nominal', 'Nominal', 'Low', 'Nominal', 'High', 'Nominal', 'Very_High', 'Low', 'Nominal', 'High', 'Nominal', 'Low', '70', '278']\n",
            "['Very_High', 'High', 'High', 'Very_High', 'Very_High', 'Nominal', 'Nominal', 'Very_High', 'Very_High', 'Very_High', 'Nominal', 'High', 'High', 'High', 'Low', '227', '1181']\n",
            "['Nominal', 'High', 'High', 'Very_High', 'High', 'Low', 'High', 'High', 'Nominal', 'High', 'Low', 'High', 'High', 'Nominal', 'Low', '177.9', '1248']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '115.8', '480']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '29.5', '120']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '19.7', '60']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '66.6', '300']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '5.5', '18']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '10.4', '50']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '14', '60']\n",
            "['Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', '16', '114']\n",
            "['High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', '6.5', '42']\n",
            "['Nominal', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', '13', '60']\n",
            "['Nominal', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', '8', '42']\n",
            "['Nominal', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'Nominal', 'High', 'High', 'High', 'Nominal', '90', '450']\n",
            "['High', 'Nominal', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', '15', '90']\n",
            "['High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', '38', '210']\n",
            "['Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', '10', '48']\n",
            "['Nominal', 'Very_High', 'High', 'Very_High', 'Very_High', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'Low', 'High', 'Very_High', 'Very_High', 'Low', '161.1', '815']\n",
            "['Nominal', 'Very_High', 'High', 'Very_High', 'Very_High', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'Low', 'High', 'Very_High', 'Very_High', 'Low', '48.5', '239']\n",
            "['Nominal', 'Very_High', 'High', 'Very_High', 'Very_High', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'Low', 'High', 'Very_High', 'Very_High', 'Low', '32.6', '170']\n",
            "['Nominal', 'Very_High', 'High', 'Very_High', 'Very_High', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'Low', 'High', 'Very_High', 'Very_High', 'Low', '12.8', '62']\n",
            "['Nominal', 'Very_High', 'High', 'Very_High', 'Very_High', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'Low', 'High', 'Very_High', 'Very_High', 'Low', '15.4', '70']\n",
            "['Nominal', 'Very_High', 'High', 'Very_High', 'Very_High', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'Low', 'High', 'Very_High', 'Very_High', 'Low', '16.3', '82']\n",
            "['Nominal', 'Very_High', 'High', 'Very_High', 'Very_High', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'Low', 'High', 'Very_High', 'Very_High', 'Low', '35.5', '192']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '25.9', '117.6']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '24.6', '117.6']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '7.7', '31.2']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '9.7', '25.2']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '2.2', '8.4']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '3.5', '10.8']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '8.2', '36']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Low', '66.6', '352.8']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Extra_High', 'Low', 'Low', 'High', 'Very_High', 'Very_High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', '150', '324']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'High', 'Nominal', 'Nominal', 'Nominal', 'Very_Low', 'Nominal', 'Nominal', 'Nominal', '100', '360']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Nominal', 'High', 'Low', 'High', 'High', 'High', 'Low', 'Very_Low', 'Nominal', 'Nominal', 'Nominal', '100', '215']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'High', 'Very_High', 'Very_High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', '100', '360']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', '15', '48']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Extra_High', 'Low', 'Low', 'High', 'High', 'Nominal', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', '32.5', '60']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'High', 'High', 'High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', '31.5', '60']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', '6', '24']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'High', 'Very_High', 'Nominal', 'Nominal', 'Low', 'Nominal', 'Nominal', 'Nominal', '11.3', '36']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'High', 'Very_High', 'Very_High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', '20', '72']\n",
            "['Nominal', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'High', 'Very_High', 'High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', '20', '48']\n",
            "['High', 'Low', 'High', 'Extra_High', 'Extra_High', 'Low', 'High', 'High', 'High', 'High', 'Nominal', 'High', 'High', 'High', 'Nominal', '7.5', '72']\n",
            "['High', 'Low', 'High', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'Nominal', 'High', 'Nominal', 'Nominal', 'High', 'Very_Low', 'Nominal', '302', '2400']\n",
            "['High', 'Nominal', 'High', 'High', 'High', 'Low', 'High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Low', 'Very_High', 'Nominal', '370', '3240']\n",
            "['High', 'Nominal', 'High', 'High', 'High', 'Low', 'High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Low', 'Very_High', 'Nominal', '219', '2120']\n",
            "['High', 'Nominal', 'High', 'High', 'High', 'Low', 'High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Low', 'Very_High', 'Nominal', '50', '370']\n",
            "['High', 'Nominal', 'Very_High', 'High', 'High', 'Low', 'High', 'High', 'Nominal', 'Nominal', 'High', 'High', 'Low', 'Very_High', 'High', '101', '750']\n",
            "['Nominal', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Low', 'Nominal', 'High', 'Very_High', 'Very_High', 'Low', 'High', 'High', 'Nominal', 'Nominal', '190', '420']\n",
            "['Nominal', 'Nominal', 'High', 'Nominal', 'High', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', 'High', '47.5', '252']\n",
            "['Very_High', 'Nominal', 'Extra_High', 'High', 'High', 'Low', 'Low', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', 'Low', 'High', 'Nominal', '21', '107']\n",
            "['Low', 'Nominal', 'Nominal', 'Nominal', 'Nominal', 'Low', 'Low', 'High', 'High', 'Very_High', 'Nominal', 'High', 'Low', 'Low', 'High', '423', '2300']\n",
            "['High', 'High', 'Nominal', 'Nominal', 'Nominal', 'Low', 'Low', 'Nominal', 'High', 'High', 'Nominal', 'High', 'Nominal', 'Nominal', 'Nominal', '79', '400']\n",
            "['High', 'High', 'Low', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'High', 'Nominal', 'Nominal', 'Nominal', 'High', 'Nominal', 'Nominal', '284.7', '973']\n",
            "['Nominal', 'High', 'Low', 'Nominal', 'Nominal', 'High', 'Nominal', 'High', 'High', 'Nominal', 'Nominal', 'Nominal', 'High', 'High', 'Nominal', '282.1', '1368']\n",
            "['Nominal', 'High', 'High', 'Very_High', 'Nominal', 'Nominal', 'High', 'High', 'High', 'High', 'Nominal', 'High', 'Low', 'Low', 'High', '78', '571.4']\n",
            "['Nominal', 'High', 'High', 'Very_High', 'Nominal', 'Nominal', 'High', 'High', 'High', 'High', 'Nominal', 'High', 'Low', 'Low', 'High', '11.4', '98.8']\n",
            "['Nominal', 'High', 'High', 'Very_High', 'Nominal', 'Nominal', 'High', 'High', 'High', 'High', 'Nominal', 'High', 'Low', 'Low', 'High', '19.3', '155']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtfupr9JInhf",
        "outputId": "6aaebfec-4fb7-4cb4-fcf8-e2538f081569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Preprocessing\n",
        "# Encoding categorical variables (if any)\n",
        "# Feature Scaling\n",
        "# Filling missing values (if any)\n",
        "data=data.astype(\"str\")\n",
        "#print(data.shape)\n",
        "y=data[:,16].astype(\"f\")\n",
        "x=data[:,:16].astype(\"str\")\n",
        "#print(x)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(x[:,0])\n",
        "#print(integer_encoded)\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "X = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "\n",
        "    \n",
        "for i in range(1,x.shape[1]-1):\n",
        "    label_encoder = LabelEncoder()\n",
        "    integer_encoded = label_encoder.fit_transform(x[:,i])\n",
        "    #print(integer_encoded)\n",
        "\n",
        "    onehot_encoder = OneHotEncoder(sparse=False)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "    X=np.column_stack((X,onehot_encoded))\n",
        "\n",
        "X=np.column_stack((X,x[:,15]))\n",
        "#X=np.append(X,x[:,15],axis=1)\n",
        "#print(X.shape)\n",
        "#print(y.shape)\n",
        "#print(X)\n",
        "#print(y)\n",
        "\n",
        "X[:,55] = preprocessing.normalize(X[:,55].reshape(1,-1))\n",
        "#X = preprocessing.normalize(X)\n",
        "print(X)\n",
        "print(X.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['0.0' '0.0' '1.0' ... '1.0' '0.0' '0.07395893633170382']\n",
            " ['0.0' '0.0' '1.0' ... '1.0' '0.0' '0.07395893633170382']\n",
            " ['0.0' '0.0' '0.0' ... '1.0' '0.0' '0.23983826496138239']\n",
            " ...\n",
            " ['0.0' '0.0' '1.0' ... '0.0' '0.0' '0.08241138619818425']\n",
            " ['0.0' '0.0' '1.0' ... '0.0' '0.0' '0.012044741059734623']\n",
            " ['0.0' '0.0' '1.0' ... '0.0' '0.0' '0.020391535302884053']]\n",
            "(61, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylhtVecl-5kT",
        "outputId": "a8f97a71-9ef4-49ed-fe5a-e3c484120208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Apply feature subset selection techniques \n",
        "X = SelectKBest(f_regression, k=56).fit_transform(X.astype(\"f\"), y)\n",
        "print(X.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(61, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13owZH7mIpZp",
        "outputId": "d2a274cb-dd68-4e27-c4a8-9337dc190d2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Divide the dataset to training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.astype(\"f\"), y, test_size=0.33, random_state=42)\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         1.         ... 1.         0.         0.07395893]\n",
            " [0.         0.         1.         ... 1.         0.         0.07395893]\n",
            " [0.         0.         0.         ... 1.         0.         0.23983827]\n",
            " ...\n",
            " [0.         0.         1.         ... 0.         0.         0.08241139]\n",
            " [0.         0.         1.         ... 0.         0.         0.01204474]\n",
            " [0.         0.         1.         ... 0.         0.         0.02039154]]\n",
            "[ 278.   278.  1181.  1248.   480.   120.    60.   300.    18.    50.\n",
            "   60.   114.    42.    60.    42.   450.    90.   210.    48.   815.\n",
            "  239.   170.    62.    70.    82.   192.   117.6  117.6   31.2   25.2\n",
            "    8.4   10.8   36.   352.8  324.   360.   215.   360.    48.    60.\n",
            "   60.    24.    36.    72.    48.    72.  2400.  3240.  2120.   370.\n",
            "  750.   420.   252.   107.  2300.   400.   973.  1368.   571.4   98.8\n",
            "  155. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KEJ1BB8a5xQ",
        "outputId": "4f5dd820-8ddb-4bc4-ce98-2db07ef8e135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Build regression models \n",
        "regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred=regr.predict(X_test)\n",
        "mse = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
        "rmse = math.sqrt(mse)\n",
        "print(\"Root Mean Squared Error Support Vector Machine: \",rmse)\n",
        "print()\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "mse = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
        "rmse = math.sqrt(mse)\n",
        "print(\"Root Mean Squared Error Linear Regression: \",rmse)\n",
        "\n",
        "\n",
        "clf = tree.DecisionTreeRegressor()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "mse = sklearn.metrics.mean_squared_error(y_test, y_pred)\n",
        "rmse = math.sqrt(mse)\n",
        "print(\"Root Mean Squared Error Decision Tree: \",rmse)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error Support Vector Machine:  561.043882552876\n",
            "\n",
            "Root Mean Squared Error Linear Regression:  291.52793873400884\n",
            "Root Mean Squared Error Decision Tree:  330.2590930033951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hZF7xcjbdAF"
      },
      "source": [
        "##Task 2: Ensemble regression models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHOGKAXiCsSN",
        "outputId": "8d989a17-3b91-4799-b79e-50bcb40bd7d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Ensemble the regression models\n",
        "est = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0, loss='ls').fit(X_train, y_train)\n",
        "print('GradientBoostingRegressor MSE : ',mean_squared_error(y_test, est.predict(X_test)))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientBoostingRegressor MSE :  93540.30280587511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mxX68_zX8Zl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}