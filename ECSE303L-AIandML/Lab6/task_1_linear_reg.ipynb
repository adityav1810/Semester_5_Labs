{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3tWQnVjqfFwv"
   },
   "source": [
    "## Data Leakage, L1(Lasso) and L2 (Ridge) regularization using Linear Regression\n",
    "\n",
    "We will use cross validation, lasso and ridge regression in this lab.\n",
    "\n",
    "Specifically speaking, <br>\n",
    "Regularization basically adds the penalty as model complexity increases.<br>\n",
    "Cross validation is used to evaluate how well our model can generalize on the dataset. <br>\n",
    "\n",
    "We will be using r2 score in this lab. It provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model.\n",
    "\n",
    "\n",
    "In this task, we will explore the following things on linear regression model:\n",
    "- Cross Validation\n",
    "- L1 regularization (Lasso regression)\n",
    "- L2 regularization (Ridge regression)\n",
    "\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at \"data/bike.csv\" in the respective challenge's repo.<br>\n",
    "\n",
    "The dataset is __modified version__ of the dataset 'bike.csv' provided by UCI Machine Learning repository.\n",
    "\n",
    "Original dataset: https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset\n",
    "\n",
    "#### Objective\n",
    "To learn about how cross validation, L1 regularization and L2 regularization work.\n",
    "\n",
    "#### Tasks\n",
    "- load the dataset.\n",
    "- perform pre-processing on the data.\n",
    "- remove registered feature and keep the casual feature to understand data leakage.\n",
    "- construct train and test dataset.\n",
    "- create a linear regression model.\n",
    "- check the r2 score of the initial linear regression model on train and test dataset\n",
    "- observe distribution of weights in the initial linear regression model. \n",
    "- split the dataset into k consecutive folds.\n",
    "- calculate cross validation score for the k fold and check how well our model can generalize on the training dataset.\n",
    "- checking the variance threshold of dataset and remove features with low variance.\n",
    "- apply L1 regularization on the dataset and check the r2_score.\n",
    "- visualize the distribution of weights on the lasso regression model.\n",
    "- apply L2 regularization on the dataset and check the r2_score.\n",
    "- visualize the distribution of weights on the ridge regression model. \n",
    "\n",
    "#### Further fun\n",
    "- apply RFE on the dataset to automatically remove uneccessary features which would prevent overfitting.\n",
    "- don't remove casual and registered features and check the effect of data leakage on the model\n",
    "- implement lasso and ridge regression without using inbuilt librarires.\n",
    "- apply elastic net to visualize the effect of both ridge and lasso regression.\n",
    "\n",
    "\n",
    "#### Helpful links\n",
    "- Cross validation : https://machinelearningmastery.com/k-fold-cross-validation/#:~:text=Cross%2Dvalidation%20is%20a%20resampling,k%2Dfold%20cross%2Dvalidation.\n",
    "- Cross validation: https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "- L1 and L2 regularization : https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b\n",
    "- L1 and L2 regularization : https://www.youtube.com/watch?v=9lRv01HDU0s&list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&index=30&t=904s\n",
    "- r2_score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score\n",
    "- pd.get_dummies() and One Hot Encoding: https://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example\n",
    "- Data Leakage : \"https://machinelearningmastery.com/data-leakage-machine-learning/\n",
    "- sklearn k-fold : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "- sklearn cross_val_score : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html?highlight=cross_val_score#sklearn.model_selection.cross_val_score\n",
    "- sklearn lasso regression : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html?highlight=lasso#sklearn.linear_model.Lasso\n",
    "- sklearn ridge regression : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html?highlight=ridge#sklearn.linear_model.Ridge\n",
    "- RFE : https://machinelearningmastery.com/rfe-feature-selection-in-python/\n",
    "- RFE sklearn : https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    "- Use slack for doubts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRl7KPgwjRHI"
   },
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn processing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Sklearn linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sklearn regression model evaluation functions\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Perform feature selection using a variance threshold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Feature selection using Recursive Feature Elimimation\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vq1jiQz-kIpA"
   },
   "outputs": [],
   "source": [
    "#load the data and inspect the first 5 rows\n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pw5T1NvekL65"
   },
   "outputs": [],
   "source": [
    "# print the data types of each feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RE0sjCi4kREL"
   },
   "outputs": [],
   "source": [
    "# check for null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWJz8TAgketK"
   },
   "outputs": [],
   "source": [
    "# print out the unique values of the features ['season', 'year', 'weather', 'promotion_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nkDe68NkyZ2"
   },
   "outputs": [],
   "source": [
    "# print out the value counts (frequency of occurence) of the unique values in these features ['season', 'year', 'weather', 'promotion_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yIsIIQWFmJRK"
   },
   "outputs": [],
   "source": [
    "# print the shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xXsOHMilNTz"
   },
   "outputs": [],
   "source": [
    "# drop the feature 'id' as it has no information to deliver.\n",
    "\n",
    "data = data.drop(?, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4BXZ-_qmNYh"
   },
   "outputs": [],
   "source": [
    "# print the shape of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1G-eQ8ULmO3J"
   },
   "outputs": [],
   "source": [
    "# one hot encode the categorical columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qcf6heimmZaQ"
   },
   "outputs": [],
   "source": [
    "# print the shape of data \n",
    "# notice the increase in the no. of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLOkfanFfWDK"
   },
   "source": [
    "Notice that our target feature \"cnt\" is the sum of the features \"registered\" + \"casual\"<br>\n",
    "\n",
    "To avoid data leakage remove the feature \"casual\" for the training purpose. <br>\n",
    "\n",
    "To understand more about data leakage refer the article mentioned in the uselful links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZ2HK7RGmO63"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into X and y\n",
    "# While loading data into X drop the columns \"cnt\" and \"casual\". \n",
    "X = ?\n",
    "\n",
    "# notice the target variable is 'cnt'\n",
    "y = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y1kT6PpR4F1s"
   },
   "outputs": [],
   "source": [
    "# store the names of the training features / name of the columns used for training. [Very important step for visualization later.]\n",
    "\n",
    "train_columns = list(X.columns)\n",
    "print(train_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6blYZrz7mPBG"
   },
   "outputs": [],
   "source": [
    "# Apply scaling if our data is spread across wide differences of range values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Feyrb90p3qf8"
   },
   "outputs": [],
   "source": [
    "# print the type of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jtau8HV73t7Y"
   },
   "source": [
    "Note : <br>\n",
    "Type of X should be pandas dataframe.\n",
    "If not then convert X into pandas DataFrame object before proceeding further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5II0AWy4AHK"
   },
   "outputs": [],
   "source": [
    "# convert X into pandas Dataframe\n",
    "# in the parameters specify columns = train_columns.\n",
    "\n",
    "X = pd.DataFrame(X, columns = train_columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ad4MfGe1mPDk"
   },
   "outputs": [],
   "source": [
    "# split the dataset into X_train, X_test, y_train, y_test\n",
    "# play around with test sizes.\n",
    "\n",
    "test_size = ?\n",
    "X_train, X_test, y_train, y_test = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6czlxW2tnQqP"
   },
   "outputs": [],
   "source": [
    "# print the shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-lp9O74nUm7"
   },
   "outputs": [],
   "source": [
    "# build the Linear Regression model.\n",
    "\n",
    "model = ?\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(?, ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ga_f-66JoVri"
   },
   "outputs": [],
   "source": [
    "# print the score on training set\n",
    "y_pred_train = model.predict(?)\n",
    "print(\"On Training set : \", r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKmlrtpDoilu"
   },
   "outputs": [],
   "source": [
    "# print the score on the test set\n",
    "y_pred_test = model.predict(?)\n",
    "print(\"On testing set : \", r2_score(?, ?))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYyTP91_pB-u"
   },
   "source": [
    "Do not edit the code given below. Observe the distribution of weights. \n",
    "Which feature has the maximum coefficient ? <br>\n",
    "Keep this figure as a base reference for visualizing the effects of l1-norm and l2-norm later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ck8Vx1bWozcf"
   },
   "outputs": [],
   "source": [
    "# custom summary function to plot the coefficients / weightage of the features.\n",
    "def custom_summary(model, column_names, title):\n",
    "    '''Show a summary of the trained linear regression model'''\n",
    "\n",
    "    # Plot the coeffients as bars\n",
    "    fig = plt.figure(figsize=(8,len(column_names)/3))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    rects = plt.barh(column_names, model.coef_,color=\"lightblue\")\n",
    "\n",
    "    # Annotate the bars with the coefficient values\n",
    "    for rect in rects:\n",
    "        width = round(rect.get_width(),4)\n",
    "        plt.gca().annotate('  {}  '.format(width),\n",
    "                    xy=(0, rect.get_y()),\n",
    "                    xytext=(0,2),  \n",
    "                    textcoords=\"offset points\",  \n",
    "                    ha='left' if width<0 else 'right', va='bottom')        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuyEBDrYotzb"
   },
   "outputs": [],
   "source": [
    "# coefficients plot\n",
    "# let's call the above custom function.\n",
    "\n",
    "custom_summary(model, train_columns, \"Linear Regression coefficients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E77vWyd7plQ2"
   },
   "outputs": [],
   "source": [
    "# evaluate the model with k = 10 Fold Cross validation\n",
    "\n",
    "folds = KFold(n_splits = 10, shuffle = True, random_state = 100)\n",
    "results = cross_val_score(?, ?, ?, scoring = 'r2', cv = folds)\n",
    "\n",
    "print(type(model).__name__)\n",
    "print(\"kFoldCV:\")\n",
    "print(\"Fold R2 scores:\", results)\n",
    "print(\"Mean R2 score:\", results.mean())\n",
    "print(\"Std R2 score:\", results.std())\n",
    "print(\"Generalizability on training set : \", results.mean(), \" +/- \", results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNVstf3MRWTS"
   },
   "source": [
    "Feature Selection using Variance Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fWmra-LRSvk"
   },
   "outputs": [],
   "source": [
    "print(\"Original shape of X_train : \", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdfMwVybRl9o"
   },
   "outputs": [],
   "source": [
    "# check the variance of X.\n",
    "# Note the type(X) should be a pandas DataFrame as stated earlier.\n",
    "\n",
    "X.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kk36hVk_Rv6l"
   },
   "source": [
    "Remove low variance features using Variance Threshold. \n",
    "\n",
    "Note : If the variance is less, it implies the values of that particular feature spans limited range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RkbbmcuRtkJ"
   },
   "outputs": [],
   "source": [
    "# play around with the threshold values\n",
    "\n",
    "sel = VarianceThreshold(threshold = (0.01))\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bk525DOySWJp"
   },
   "outputs": [],
   "source": [
    "# do not edit.\n",
    "\n",
    "selected_features = list(X_train.columns[sel.get_support()])\n",
    "print(\"Selected features : \", selected_features)\n",
    "print(\"Removed features : \", list(X_train.columns[~sel.get_support()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ci3BFPnE5ex4"
   },
   "outputs": [],
   "source": [
    "# Delete the removed features from the train_columns list.\n",
    "\n",
    "for i in removed_features:\n",
    "  train_columns.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1AQhlAhSXI5"
   },
   "outputs": [],
   "source": [
    "#transform / remove the low variance features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UH8mZBs3S-i3"
   },
   "source": [
    "## Lasso Regression : L1 - norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XTVvk4gS98-"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(?, ?, test_size = ?, random_state = 100)\n",
    "\n",
    "# hyperparamater alpha : controls the degree of penaliation.\n",
    "# play around with alpha values.\n",
    "alpha = 1.0\n",
    "\n",
    "#create the model\n",
    "model_lasso = Lasso(alpha = alpha)\n",
    "\n",
    "#fit the model on training data\n",
    "model_lasso.fit(?, ?)\n",
    "\n",
    "#calculate the score on training data\n",
    "y_pred_train = model_lasso.predict(?)\n",
    "print(\"On train set : \", r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PD4NpuxYTWoV"
   },
   "outputs": [],
   "source": [
    "#evaluate the model on testing data\n",
    "y_pred_test = model_lasso.predict(?)\n",
    "print(\"On test set : \", r2_score(y_test, ?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bN7w1V5hT2Dp"
   },
   "outputs": [],
   "source": [
    "# visualize the coefficients.\n",
    "# compare the results with the plot obtained earlier.\n",
    "\n",
    "custom_summary(model_lasso, train_columns, \"Lasso Regression Coefficients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsjziyZzUS8P"
   },
   "source": [
    "We can see that Lasso regression has automatically done a lot of feature selection. Some columns might have zero coefficients. It has been effectively removed. <br> \n",
    "The model is much more interpretable than the baseline linear regression model.\n",
    "<br>\n",
    "Hence, Lasso regression has embedded Feature Selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O9IlW2V2UfD0"
   },
   "source": [
    "# Ridge Regression : L2 - norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6PRlLONUckx"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# hyperparamater alpha : controls the degree of penaliation.\n",
    "# play around with alpha values.\n",
    "alpha = 1.0\n",
    "\n",
    "#create the model\n",
    "model_ridge = Ridge(alpha = ?)\n",
    "\n",
    "#fit the model on training data\n",
    "model_ridge.fit(?, ?)\n",
    "\n",
    "#calculate the score on training data\n",
    "y_pred_train = model_ridge.predict(?)\n",
    "print(\"On train set : \", r2_score(y_train, ?))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jzukav_PVTG2"
   },
   "outputs": [],
   "source": [
    "#evaluate the model on testing data\n",
    "y_pred_test = model_ridge.predict(?)\n",
    "print(\"On test set : \", r2_score(y_test, ?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c39ZBnmvVYSA"
   },
   "outputs": [],
   "source": [
    "# visualize the coefficients.\n",
    "# compare the results with the plot obtained earlier.\n",
    "\n",
    "custom_summary(model_ridge, train_columns, \"Ridge Regression Coefficients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqLF3812VefE"
   },
   "source": [
    "Ridge regression doesn't drive smaller coefficients to 0 hence it doesn't possess internal feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUCm0xOc6inT"
   },
   "source": [
    "Points to Ponder ! [Optional]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9FHk5sw6nLb"
   },
   "source": [
    "Did you notice the highest dependency on the feature \"registered\" if you haven't removed it till now ?\n",
    "\n",
    "Since our target is \"cnt\" which is the simple combination of \"registered\" and \"casual\".\n",
    "\n",
    "we have removed \"casual\", but the model was smart enough to predict the target \"cnt\" simply from one feature \"registered\" itself. \n",
    "\n",
    "This is the classic example of Data Leakage. So the aim here is not to make 99 percent accurate predictions, the aim is to take into account the factors for making predictions.\n",
    "\n",
    "So, to get a detailed report, we should avoid data leakage thereby removing both the features \"registered\" and \"casual\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4euMcAFR6kLG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task1_LinearRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
